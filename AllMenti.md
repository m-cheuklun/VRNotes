# Week 1 - History of XR, RV Continuum

## Q1) What is the price of the original Oculuc DK1?
- 300
- 500
- 1100
- 1500
- 2000

__Answer__ 
> 300

## Q2) What experience is this?

![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/1e44de9a-24c6-41fa-b60e-282c30073450)

- AR
- VR
- MR

__Answer__
> [AR]

## Q3) What experience is this?

![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/f0e5444d-f633-4d52-9f19-317543837ed3)

- AR
- VR
- MR

__Answer__
> [MR]

## Q4) Where should Pokemon GO be placed in the RV Continuum?

![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/7c16f947-fddb-40ff-a16d-5a3ed2842257)
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/6ad8856e-12c6-4763-bfaf-687e4854a272)

__Answer__
> [B]
> Basing off the real-world environment, closer to Real World.

## Q5) Where should Beat Saber be placed in the RV Continuum?

![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/2daa3ff2-7bb2-4ccd-b0fe-7424817378df)
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/6ad8856e-12c6-4763-bfaf-687e4854a272)

__Answer__
> [D] or [E]
> No real-world environment, can be arguable it is not entirely virtual.
> Theory-wise, cannot be entirely virtual since it tracks your hands and user can slightly see real world through gaps in goggles.

## Q6) Where should Strava be placed in the RV Continuum?

![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/3206420f-3e84-414a-9048-b58602b154d9)
![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/6ad8856e-12c6-4763-bfaf-687e4854a272)

__Answer__
> [B]
> Closer to reality since it tracks user location.
> Not entirely real since ...[Question is below].

## Q7) Why is Strava not considered to be near the "Real Environment" end of the RV spectrum?

- It has some "Extent of World Knowledge"
- It has some "Reproduction Fidelity"
- It has some "Extent of Presence Metaphor"

__Answer__
> [It has some "Extent of World Knowledge"]
> It is trying to gather data from the real world.
> And the higher the "Extent of World Knowledge", the more virtual it is.

## Q8) What is the common public perception of the difference between AR and MR?

- They are the same
- AR refers to blending virtual objects onto the real-world
- Virtual entities in MR can interact with real-world objects

__Answer__
> [Virtual entities in MR can interact with real-world objects]
> Coined by Microsoft, that MR can interact with real-world objects.
> Showcases HoloLens as MR hardware.

![image](https://github.com/TobyIO0085/VRNotes/assets/76524945/5cf7b722-3f4c-41fc-8972-9387153566ee)

## Q9) VR was invented in the 21st Century (2001-2100)

- True
- False

__Answer__
> [False]
> Started around 1957 Sensorama and 1968 Sword of Damocles.

## Q10) Which device sparked the current rise of VR

- Sega VR
- Oculus Rift DK1
- Google Cardboard
- Oculus Quest
- Meta Quest 2

__Answer__
> Oculus Rift DK1

## 11) 3D models are extremely high quality. What dimension the RV continuum is this referring to?

- 'Extent of World Knowledge'
- 'Reproduction Fidelity'
- 'Extent of Presence Metaphor'
- 'Coherence'

__Answer__
> 'Reproduction Fidelity'

## 12) The 3D virtual dogs are able to jump onto the real table seen through the camera. What dimension of the RV continum is this referring to?

- 'Extent of World Knowledge'
- 'Reproduction Fidelity'
- 'Extent of Presence Metaphor'
- 'Coherence'

__Answer__
> 'Extent of World Knowledge'

## 13) The stereo optics provide a perception of depth through an LCD display. What dimension of the RV continuum is this referring to?

- 'Extent of World Knowledge'
- 'Reproduction Fidelity'
- 'Extent of Presence Metaphor'
- 'Coherence'

__Answer__
> 'Extent of Presence Metaphor'

## 14) For a moment I believed that I was actually 1000ft above ground. What dimension of the RV continuum is this referring to?

- 'Extent of World Knowledge'
- 'Reproduction Fidelity'
- 'Extent of Presence Metaphor'
- 'Coherence'

__Answer__
> 'Coherence'

# Week 2 - Immersive experiences

## Q1) Which of the following describes immersion from a systems perspective?

- Wide FOV
- Higher spatial presence
- Higher place illusion
- 8K Resolution display
- Lower cybersickness
- 6-DOF inside-out tracking

__Answer__
> Wide FOV
> 8K Resolution display
> 6-DOF inside-out tracking

## Q2) Which of the following describes immersion from an experiential perspective?

- Wide FOV
- Higher spatial presence
- Higher place illusion
- 8K Resolution display
- Lower cybersickness
- 6-DOF inside-out tracking

__Answer__
> Higher spatial presence
> Higher place illusion
> Lower cybersickness

## Q3) What experiential constructs were analysed in the user study in the paper on "Exploring Gameplay Experiences on the Oculus Rift"?

- Flow
- Presence
- Place illusion
- Plausibility illusion
- Cybersickness

__Answer__
> Flow
> Cybersickness

## Q4) What quantitative data was analysed in the user study in the paper on "Exploring Gameplay Experiences on the Oculus Rift"?

- Flow
- Presence
- Cybersickness
- Physiological measures
- User behaviors

__Answer__
> Flow
> Physiological measures

## Q5) What quantitative data was analysed in the user study in the paper on "Understanding User Experiences Across VR Walking-in-place Locomotion Methods"?

- Flow
- Presence
- Cybersickness
- Physiological measures
- User behaviors

__Answer__
> Flow
> Presence
> Cybersickness

## Q6) What qualitative data was analysed in the user study in the paper on "Understanding User Experiences Across VR Walking-in-place Locomotion Methods"?

- Flow
- Presence
- Cybersickness
- Physiological measures
- User behaviors

__Answer__
> Flow
> Presence
> Cybersickness
> User behaviors

## Q7) What type of data allows us to answer this research question in the most direct and convincing fashion?

![Is the VR version more immersive than the desktop version of myApp?](/images/IsVRmoreImmersiveThanMyPC.png)

- Observations
- Think-aloud during the experience
- Validated Questionaires
- Post-experience interviews
- Physiological sensing
- Telemetry

__Answer__ 
> Validated Questionaires

## Q8) What is the best type of data to answer this research question?

![What user experiences does the VR classroom intervention afford during the class?](/images/UserExperienceDoesVRAffort.png)

- Observations
- Think-aloud during the experience
- Questionaires
- Post-experience interviews
- Physiological sensing
- Telemetry

__Answer__
> Observations
> Think-aloud during the experience
> Post-experience interviews

## Q9) Which of the following is NOT a symptom of cybersickness?

- Blurred vision
- Eyestrain
- Giddiness
- Loss of self-consciousness
- Vertigo

__Answer__
> Loss of self-consciousness

## Q10) "This one feels dizzier than the previous one." - What dimension of cybersickness is this?

- Disorientation
- Nausea
- Oculomotor
- Involvement
- Realness

__Answer__
> Disorientation

## Q11) "I find it very straining on my eyes to look at stuff in the scene after a short while" - What dimension of cybersickness is this?

- Disorientation
- Nausea
- Oculomotor
- Involvement
- Realness

__Answer__
> Oculomotor

## Q12) Which cybersickness questionnaire is best when I need to use the results to inform V2.0 development of my VR

- SSQ
- CSQ
- VRSQ

__Answer__
> CSQ
> VRSQ

## Q13) Which cybersickness questionnaire should I use when I need to compare my results with a pool of prior research studies from others?

- SSQ
- CSQ
- VRSQ

__Answer__
> SSQ

## Q14) What is the type of experience being described here?

![I was surprised that 30 minutes already passed after I took off the headset. I thought I only played the game for 5 minutes.](/images/FlowExperience.png)

- Presence
- Flow
- Cybersickness

__Answer__
> Flow

## Q15) What is the type of experience being described here?

> My head knocked into the (real) wall as I tried to dodge the (virtual) ball coming towards me. My mum was actually telling me how close I got to the wall but I was totally unaware that she was talking

- Presence
- Flow
- Cybersickness

__Answer__
> Presence

## Q16) What is the type of experience being described here?

> My friends were telling me how stupid I looked when I was playing the VR game. When I was in the game, I wasn't aware at all how I looked, I just wanted to conquer the challenges in there.

- Presence
- Flow
- Cybersickness

__Answer__
> Flow

## Q17) What is the main affordance on a haptic glove for an experienced VR user?

- Reach out to touch things in the virtual environment
- Pick up the VR controller to interact with the virtual environment
- Wave hand in the air
- Hug another character in the virtual environment

__Answer__
> Reach out to touch things in the virtual environment

## Q18) Which design provides the right affordance for a door that is meant to be pushed

- Door with a large handle
- Door with a small handle
- Door with no handle and a flat metal plate
- Door with a twist knob
- Door with a large sign that says "PUSH"

__Answer__
> Door with no handle and a flat metal plate

# Week 4 - Development tools

## Q1) I need to use a WebXR-compliant framework for my Team Project

- Yes
- No

__Answer__
> No

## Q2) I should build my Team Project on top of the existing UniverseSITy codebase

- Yes
- No

__Answer__
> No

## Q3) We will be assessed more favourably if we can demonstrate higher levels of immersion from our evaluation

- Yes
- No

__Answer__
> No

## Q4) We will be assessed more favourably if our project aligns with UniverseSITy theme better (e.g. use real SIT campus 3D model)

- Yes
- No

__Answer__
> No

## Q5) We will be assessed more favourable if we demonstrate implementation efforts that are clearly aligned with immersion goals

- Yes
- No

__Answer__
> Yes

## Q6) When I run console.log("debug"), where should I see this "debug" message?

- Mac terminal
- Windows Command Prompt
- Web browser's Javascript Console
- ADB's logcat

__Answer__
> Mac terminal
> Windows Command Prompt
> Web browser's Javascript Console

## Q7) When connecting the Meta Quest, there is no prompt to enable connection and I can't see developer options in the settings. What is the likely issue?

- Did not connect a USB data cable
- Headset low battery
- Did not tap the Build Number 7 times in the settings
- Did not enable Developer Mode on the Meta app on the phone

__Answer__
> Did not enable Developer Mode on the Meta app on the phone

## Q8) Where is createScene(...) normally defined?

- main.ts
- app.ts
- index.html
- package.json
- package-lock.json
- tsconfig.json

__Answer__
> app.ts

## Q9) You want to add a custom script as part of your BabylonJS project test workflow. Which file should you modify?

- main.ts
- app.ts
- index.html
- package.json
- package-lock.json
- tsconfig.json

__Answer__
> package.json

## Q10) Which file should you add to your team's version control if you want the project dependencies to have the same exact versions across your team?

- main.ts
- app.ts
- index.html
- package.json
- package-lock.json
- tsconfig.json

__Answer__
> package-lock.json

## Q11) What does the following Babylon.js snippet accomplish?

>   const xr = await scene.createDefaultXRExperienceAsync({
>       uiOptions: {
>           sessionMode: "immersive-vr",
>       },
>   });

- Initializes typical components for hybrid XR (AR & VR) experience
- Makes a non-blocking method call to initialize components
- Creates a default BabylonJS scene with a sphere
- Waits for all components to complete initialization before continuing

__Answer__
> Makes a non-blocking method call to initialize components

## Q12) What is the main reason for choosing WebXR as the core development stack?

- It provides the best immersion
- Our research is based on it
- It is open-source and meant for accessible cross-platform applications
- Most immersive applications are built with it
- It is a robust API and has little issues

__Answer__
> It is open-source and meant for accessible cross-platform applications

## Q13) What is the optimal development tool for this project?

> You are engaged by a mining company to build a VR system for training their own miners to operate in a coal mine. They have funds to purchase any necessary hardware you propose that is suitable and within reasonable budget. They need the working system delivered within a short 6 months time. Which tool is most suitable for you to base your development on?

- Unity
- OpenXR SDK in C++
- Babylon.js
- CoSpaces
- Blender

__Answer__
> Unity

## Q14) What is the optimal development tool for this project?

> You are building your own metaverse application, an immersive social network that aims to allow as many users as possible to participate in, using different platforms and devices. You have limited funds as an individual of course, and aim to spend as little as possible on development. Which tool is most suitable for you to base your development on?

- Unity
- OpenXR SDK in C++
- Babylon.js
- CoSpaces
- Blender

__Answer__
> Babylon.js

## Q15) What standard to focus on?

- OpenGL
- WebGL
- WebXR
- OpenXR
- OpenCL
- Vulkan

__Answer__
> OpenXR

# Week 5 - Hardware and software components

## Q1) What is the main difference between the hardware in a modern smartphone and a HMD?

- Display
- Magnifier lens
- CPU
- GPU
- Cameras
- Motion sensors

__Answer__
> Magnifier lens

## Q2) In the schematic HMD diagram, where is the "eye relief"?

![Where is eye relief at?](/images/WhereIsEyeRelief.png)

__Answer__
> e

## Q3) In the schematic HMD diagram, where is the width of the virtual image?

![Where is the width of the virtual image](/images/WhereIsWidthOfVirtualImage.png)

__Answer__
> a

## Q4) In HMDs, what effect will changing the focal length of the lens have?

- Height of the HMD display
- Depth of the HMD display
- Depth of the view frustrum's near plane
- Depth of the virtual image generated

__Answer__
> Depth of the virtual image generated

## Q5) The perspective matrix for rendering in HMDs is the same for both eyes

- True
- False

__Answer__
> False

## Q6) The view matrix for rendering in HMDs is the same for both eyes

- True
- False

__Answer__
> False

## Q7) What is a valid property of the view frustrum generated by typical HMDs?

- Volume is vertically symmetric only
- Volume is horizontally symmetric only
- Volume is both vertically and horizontally symmertric
- There is no symmetry in the volume

__Answer__
> Volume is vertically symmetric only

## Q8) What is a result of reducing the eye relief?

- Increased distance between lens to virtual image
- Decreased distance between lens to virtual image
- Increased FOV
- Decreased FOV

## Q9) Which object is easier for the user to reach out and grab with his/her hands?

![Which object is easier to grab?](/images/WhichEasierToGrab.png)

__Answer__
> A

## Q10) Which software component is the least important in the XR application described?

- Rendering
- Physics
- Input Handler
- Audio

__Answer__
> Physics

## Q11) What is the top reason for using ECS over straightforward OOP in your ap architecture

- There are lots of different virtual objects created at runtime
- All virtual objects can be constructed when the app starts
- Different virtual entities have vastly different features
- ECS has much better performance
- The features in each entity need to constantly share information

__Answer__
> There are lots of different virtual objects created at runtime

# Week 6 - Create virtual environments

## Q1) Why do we need the following code?

>   // This is usually done for skybox materials
>   skyboxMaterial.backFaceCulling = false;

- User is outside the skybox mesh viewing the back face of the textures
- User is inside the skybox mesh viewing the back face of the textures
- Skybox is a cube that is meant to be visible from all sides
- Removing backface culling is a graphics programming good practice

> User is inside the skybox mesh viewing the back face of the textures

## Q2) Which line of code makes the skybox feel like it is part of the background surrounding the user?

-   skybox = MeshBuilder.CreateBox("skyBox",{size:1000.0},scene)
-   skyboxMat.backFaceCulling = false
-   skybox.reflectionTexture.coordinatesMode = Texture.SKYBOX_MODE
-   skyboxMat = new StandardMaterial("skyBox", scene)
-   skybox.material = skyboxMaterial

>   skybox = MeshBuilder.CreateBox("skyBox",{size:1000.0},scene)

## Q3) What will the following code do?

>   Btn.onPointerUpObservable.add((evtData) => {
>       alert("Hello Button at:\n x: "
>           + evtData.x
>           + " y: "
>           + evtData.y);
>   });

- After "click" is released on Btn, show location of pointer
- After "click" down on Btn, show location of pointer
- After "click" is released on Btn, show location of Btn
- After "click" down on Btn, show location of Btn
- Compile error

> After "click" is released on Btn, show location of Btn

## Q4) This code has a runtime error. Which line is the offending line that causes this?

>   async loadModelQuiz(scene: Scene) {
>       const meshes = await SceneLoader.ImportMeshAsync(
>           "", "assets/models/", "H20.glb", scene);
>       meshes[0].position.y = -1;
>   }

- 1
- 2
- 3
- 4
- 5

> 4

## Q5) What is the function of the debugLayer in the Scene class of Babylon.js?

- Provides visual UI overlays to inspect and manipulate scene live
- Optimizes display of complex meshes during debugging step-through
- Provides debug console to run live debug script
- Shows console.log outputs overlaid on the scene

> Provides visual UI overlays to inspect and manipulate scene live

## Q6) What is the optimal approach?

> You are tasked to build a VR application to provide a virtual tour of an art gallery. The goal is to provide potential bidders with a sense of scale and depth close to viewing the real thing. What is the optimal approach for creating the virtual environment?

- Model-based
- Image-based

> Image-based

## Q7) What is the optimal approach?

> You are tasked to build a VR application for caregivers to empathise with patients suffering from dementia. The experience is intended to be primarily audio-visual with the main interaction being navigating around a house. Realism should be the focus of the immersion. What is the optimal approach for creating the virtual environment?

- Model-based
- Image-based

> Image-based

## Q8) What is the optimal approach?

> You are tasked to build a VR application to teach physics in a classroom. Kids will be able to throw virtual balls to hit cans placed at different distances and heights. Plausible interactions should be the main focus of the immersion. What is the optimal approach for creating the virtual environment?

- Model-based
- Image-based

> Model-based

# Week 8 - Interactions

## Q1) Which interaction mechanic is commonly deemed to be the most important in immersive AR, VR and MR experiences?

- Viewport Control
- Hand Gestures
- Body (Excluding hands gestures)
- All mechanics are equally important

__Answer__
> Viewport Control

## For Q2, Q3 & Q4

![VR Bioreactor Training](/images/w8-01.png)

## Q2) In the VR Bioreactor Training system, what interaction mechanics were implemented?

- Viewport Control
- Hand Gestures
- Body (Excluding hands gestures)
- All of the above

__Answer__
> Viewport Control
> Hand Gestures

## Q3) In the VR Bioreactor Training system, is viewport control a passive or active interaction mechanics?

- Passive
- Active

__Answer__
> Passive

## Q4) In the VR Bioreactor Training system, are hand gestures a passive or active interaction mechanic?

- Passive
- Active

__Answer__
> Active

## For Q5, Q6 & Q7

![360 Video Lecture](/images/w8-02.png)

## Q5) In the 360 Video Lecture, what interaction mechanics were implemented?

- Viewport Control
- Hand Gestures
- Body (Excluding hands gestures)
- All of the above

__Answer__
> Viewport Control
> Hand Gestures

## Q6) In the 360 Video Lecture, is viewport control a passive or active interaction mechanics?

- Passive
- Active

__Answer__
> Passive
> Active

## Q7) In the 360 Video Lecture, what form of interaction authenticity is the eye-gaze point-and-click mechanic?

- Natural interaction
- Artificial magical interaction
- Artificial augmented natural interaction

__Answer__
> Artificial augmented natural interaction

## Q8) Many users tend to route their hands behind the virtual saw blade when asked to place their hands in the target position? What is the primary reason?

- Limited field of view in the VR headset affecting depth perception
- The saw blade simply looks hyper-realistic
- High embodiment via realistic hand representation and precise tracking
- Difficult in accurately perceiving the virtual saw blade's position

__Answer__
> High embodiment via realistic hand representation and precise tracking

## Q9) What interaction authenticity is optimal?

> You are tasked to build a VR application to allow kids to learn physics in a classroom. Kids will be able to throw virtual balls to hit cans placed at different distances and heights. What form of interaction authenticity is optimal for this use case?

- Natural interaction
- Artificial magical interaction
- Artificial augmented natural interaction

__Answer__
> Natural interaction

## Q10) What interaction authenticity is optimal?

> You are tasked to build an MR application for people to practice taking care of a virtual pet dog in their house, to aid them with the decision of actually getting a real pet dog in the future. What form of interaction authenticity is optimal for this use case?

- Natural interaction
- Artificial magical interaction
- Artificial augmented natural interaction

__Answer__
> Natural interaction

## Q11) Which device platform is the most appropriate here?

> You are tasked to build a VR training system to train aircraft maintenance engineers to repair various aircraft parts on a virtual plane. If we are aiming for maximum immersion with natural interactions around a life-sized virtual aircraft, what device is optimal for this use case?

- Desktop
- Google Cardboard
- Meta Quest 2 (Wireless)
- HTC Vive Pro (Wired)
- Microsoft Hololens

__Answer__
> Meta Quest 2 (Wireless)

## Q12) Which device platform is the most appropriate here?

> You are tasked to build a VR cycling game that can be played on a real bike on a stationary trainer, that places you on equal standing against elite cycling professionals in a virtual Tour de France. If we are aiming for maximum immersion with augmented natural interactons, what device is optimal for this use case (assuming sweat is not a consideration)?

- Desktop
- Google Cardboard
- Meta Quest 2 (Wireless)
- HTC Vive Pro (Wired)
- Microsoft Hololens

__Answer__
> HTC Vive Pro (Wired)

## Q13) What form of GUI implementation is best suited for this use case?

> You are tasked to build a VR virtual sightseeing experience for hotel guests and the client wants to obtain feedback after each virtual trips. The client can only provide the users with Google Cardboards. What form of GUI implementation is best suited for this use case?

- GUI on a virtual paper (using a virtual pen)
- GUI on a 3D plane anchored in virtual world locations
- Real-world quiz on real paper (take off HMD when interacting)

__Answer__
> GUI on a 3D plane anchored in virtual world locations
> Real-world quiz on real paper (take off HMD when interacting)

## Q14) What form of GUI implementation is best suited for this use case?

> You are tasked to build a VR training simulation for aircraft maintenance engineers with a quizzing system to evaluate their performance during tasks. The immersion goal is to provide realistic training for typical maintenance operations. What form of GUI implementation is best suited for this use case?

- GUI on a virtual paper (using a virtual pen)
- GUI on a 3D plane anchored in virtual world locations
- Real-world quiz on real paper (take off HMD when interacting)

__Answer__
> GUI on a 3D plane anchored in virtual world locations

## Q15) You are tasked to build a VR game for persons on wheelchairs to explore famous mountains in the world. What locomotion technique is best suited for this use case?

- Teleportation
- Joystick-based
- Walking-in-place (WIP) with KatVR 360 slidemill
- Walking-in-place (WIP) with HTC Vive HMD and trackers
- Tracking real movement in physical space

__Answer__
> Teleportation

## Q16) You are tasked to build a VR escape room experience targetted at able-bodied users. Naturally, an escape room experience aims to provide maximum immersion from all aspects. What locomotion techniques is best suited for this use case?

- Teleportation
- Joystick-based
- Walking-in-place (WIP) with KatVR 360 slidemill
- Walking-in-place (WIP) with HTC Vive HMD and trackers
- Tracking real movement in physical space

__Answer__
> Tracking real movement in physical space

## Q17) As a lead developer for a new VR action-adventure game, players will engage in a series of quests across varying terrain, from dense forests to steep mountains. Movement in the game needs to be intuitive and contribute to near-realistic interactions with the environment for tasks like trekking and light stealth. To encourage sustained play without causing disorientation, what locomotion technique should you integrate into your game design?

- Teleportation
- Joystick-based
- Walking-in-place (WIP) with KatVR 360 slidemill
- Walking-in-place (WIP) with HTC Vive HMD and trackers
- Tracking real movement in physical space

__Answer__
> Walking-in-place (WIP) with HTC Vive HMD and trackers

# Week 9 - Implementing interactions

## Q1) Implement a jump action in your Babylon.js scene when the user presses the keyboard spacebar. Which trigger should you use in the ActionManager?

- OnPickTrigger
- OnInteractionEnterTrigger
- OnKeyUpTrigger
- NothingTrigger

__Answer__
> OnKeyUpTrigger

## Q2) Which implementation is the most straightforward, i.e, without reinventing the wheel?

> You want to create a button in your Babylon.js scene that, when touched, makes a door open with a creaking sound that lasts 0.5 seconds.

- Behaviors
- ActionManager
- Observables

__Answer__
> ActionManager

## Q3) In your babylon.js, you need to periodically track changes in the position of the dog object and automatically show updates on the HUD based on its proximity to different objects. Which implementation is the most straightforward, i.e, without reinventing the wheel?

- Behaviors
- ActionManager
- Observables

__Answer__
> Observables

## Q4) In your babylon.js, you need to periodically track changes in the position of the dog object and automatically show updates on the HUD based on its proximity to different objects. Which implementation is the most straightforward, i.e, without reinventing the wheel?

> In your Babylon.js scene, when a pen mesh and a paper mesh touch each other (i.e, intersect), you want to show virtual ink appearing.

- Behaviors
- ActionManager
- Observables

__Answer__
> Observables

## Q5) In your babylon.js, you need to periodically track changes in the position of the dog object and automatically show updates on the HUD based on its proximity to different objects. Which implementation is the most straightforward, i.e, without reinventing the wheel?

> In your Babylon.js scene, you want to make a dog object constantly follow your camera's movement at a set distance beside you.

- Behaviors
- ActionManager
- Observables

__Answer__
> ActionManager

## Q6) In your babylon.js, you need to periodically track changes in the position of the dog object and automatically show updates on the HUD based on its proximity to different objects. Which implementation is the most straightforward, i.e, without reinventing the wheel?

>   const onDistanceChangeObservable = new Observable<number>();
>   
>   let previousDistance: number;
>   scene.onBeforeRenderObservable.add(() => {
>       const currentDistance = Vector3.Distance( sphere.position, Vector3.Zero());
>   
>       if (currentDistance !== previousDistance) {
>           previousDistance = currentDistance;
>           onDistanceChangeObservable.notifyObservers(currentDistance);
>       }
>   });

- Behaviors
- ActionManager
- Observables

__Answer__
> Behaviors

## Q7) In total, how many observers were used here?

>   const onDistanceChangeObservable = new Observable<number>();
>   
>   let previousDistance: number;
>   scene.onBeforeRenderObservable.add(() => {
>       const currentDistance = Vector3.Distance( sphere.position, Vector3.Zero());
>   
>       if (currentDistance !== previousDistance) {
>           previousDistance = currentDistance;
>           onDistanceChangeObservable.notifyObservers(currentDistance);
>       }
>   });
>   
>   onDistanceChangeObservable.add(distance => {
>       helloText.text = ``d: ${distance.toFixed(2)}``;
>   })

- 0
- 1
- 2
- 3
- 4
- 5

__Answer__
> 2

## Q8) In total, how many observers were used here?

>   const onDistanceChangeObservable = new Observable<number>();
>   
>   let previousDistance: number;
>   scene.onBeforeRenderObservable.add(() => {
>       const currentDistance = Vector3.Distance( sphere.position, Vector3.Zero());
>   
>       if (currentDistance !== previousDistance) {
>           previousDistance = currentDistance;
>           onDistanceChangeObservable.notifyObservers(currentDistance);
>       }
>   });
>   
>   onDistanceChangeObservable.add(distance => {
>       helloText.text = ``d: ${distance.toFixed(2)}``;
>   })

- 0
- 1
- 2
- 3
- 4
- 5

__Answer__
> 2

## Q9) In total, how many observers were used here?

>   pointerDragBehavior.onDragObservable.add(eventData => {
>       console.log(sphere.position);
>   })

- 0
- 1
- 2
- 3
- 4
- 5

__Answer__
> 1

## Q10) What is the mechanics of the following code?

>   pointerDragBehavior.onDragObservable.add(eventData => {
>       console.log(sphere.position);
>   })

- It adds an Observable to pointerDragBehavior of the sphere
- It adds an Observer to the sphere
- It adds an Observer to onDragObservable of the pointerDragBehavior
- It adds and Observable to the sphere

__Answer__
> It adds an Observer to onDragObservable of the pointerDragBehavior

## Q11) Which API class in Babylon.js will allow you to easily add UI controls to easily manipulate the position, rotation, and scale of meshes in your scene?

- MultiPointerScaleBehavior
- GizmoManager
- PointerDragBehavior
- WebXRFeaturesManager

__Answer__
> GizmoManager

## Q12) What does ToTeleport do in the following Babylon.js code?

>   const teleportation = featureManager.enableFeature(
>       WebXRFeatureName.TELEPORTATION,
>       "stable",
>       {
>           xrInput: xr.input,
>           floorMeshes: [ground],
>           timeToTeleport: 2000,
>           useMainComponentOnly: true,
>           defaultTargetMeshOptions: {
>               teleportationFillColor: "#55FF99",
>               teleportationBorderColor: "blue",
>               torusArrowMaterial: ground.material,
>           },
>       },
>       true,
>       true
>   ) as WebXRMotionControllerTeleportation;

- Sets the duration of the teleportation animation
- Sets the maximum time to complete the teleportation
- Sets the minimum delay between each teleportation trigger
- Sets the time in to hold the button before teleportation triggers

__Answer__
> Sets the time in to hold the button before teleportation triggers

# Week 10 - Developing for immersion

## Q1) Which of the following describes immersion from a systems perspective?

- Wide FOV
- Higher spatial presence
- Teleportation feature
- High-fidelity graphics
- Lower cybersickness
- 6-DOF inside-out tracking

__Answer__
> Wide FOV
> Teleportation feature
> High-fidelity graphics
> 6-DOF inside-out tracking

## Q2) Which popular experiential construct(s) of immersion is/are relevant here?

- Flow
- Presence
- Cybersickness

__Answer__
> Flow
> Cybersickness

## Q3) Which of the following implementations will this design translate into?

![A design goal is to have minimal cybersickness in locomotion given the poor motion tracking fidelity of my phone in the cardboard](/images/DesignTranslate.png)

- Constrict the FOV when moving
- Test users using the VRSQ
- Test users using the IPQ
- Create a walking-in-place location feature
- Create a teleportation locomotion feature
- Create a high-fidelity realistic 3D environment

__Answer__
> Constrict the FOV when moving
> Create a teleportation locomotion feature

## Q4) What data collection methods can be appropriate here?

![A design goal is to have minimal cybersickness in locomotion given the poor motion tracking fidelity of my phone in the cardboard](/images/DesignTranslate.png)

- Let users fill in the IPQ
- Let users fill in the VRSQ
- Let users fill in the FSS
- Perform semi-structured interviews with users
- Create telemetry tracking mechanisms to observe users

__Answer__
> Let users fill in the VRSQ
> Perform semi-structured interviews with users
> Create telemetry tracking mechanisms to observe users

## Q5) Which of the following implementations will this design translate into?

![A design goal in our VR Space Simulator is for users to feel like they are "there" in the space shuttle out in space (yes the zero-gravity kind).](/images/DesignTranslate2.png)

- Constrict the FOV when moving
- Test users using the VRSQ
- Create a zero-gravity arena that simulates physical weightlessness
- Create a walking-in-place location feature
- Create a teleportation locomotion feature
- Create a high-fidelity realistic 3D environment
- Create gamification features to guide users through the experience

__Answer__
> Create a zero-gravity arena that simulates physical weightlessness
> Create a high-fidelity realistic 3D environment

## Q6) What data collection methods can be appropriate here?

![A design goal in our VR Space Simulator is for users to feel like they are "there" in the space shuttle out in space (yes the zero-gravity kind).](/images/DesignTranslate2.png)

- Let users fill in the IPQ
- Let users fill in the VRSQ
- Let users fill in the FSS
- Perform semi-structured interviews with users
- Create telemetry tracking mechanisms to observe users

__Answer__
> Let users fill in the IPQ
> Perform semi-structured interviews with users
> Create telemetry tracking mechanisms to observe users

## Q7) Which of the following implementations will this design translate into?

![A design goal is for users in our VR museum app to have a smooth engaging experience in which they naturally know what to do in each step of the experience.](/images/DesignTranslate3.png)

- Create a walking-in-place location feature
- Create a teleportation locomotion feature
- Create a high-fidelity realistic 3D environment
- Create a finger-tracked hand gestures to inspect museum artifacts
- Create gamification features to guide users through the experience

__Answer__
> Create gamification features to guide users through the experience

## Q8) What data collection methods can be appropriate here?

![A design goal is for users in our VR museum app to have a smooth engaging experience in which they naturally know what to do in each step of the experience.](/images/DesignTranslate3.png)

- Let users fill in the IPQ
- Let users fill in the VRSQ
- Let users fill in the FSS
- Perform semi-structured interviews with users
- Create telemetry tracking mechanisms to observe users

__Answer__
> Let users fill in the FSS
> Perform semi-structured interviews with users
> Create telemetry tracking mechanisms to observe users